{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":397693,"sourceType":"datasetVersion","datasetId":176381}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install remotezip tqdm opencv-python","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-03T03:16:24.929182Z","iopub.execute_input":"2024-11-03T03:16:24.929890Z","iopub.status.idle":"2024-11-03T03:16:37.791239Z","shell.execute_reply.started":"2024-11-03T03:16:24.929849Z","shell.execute_reply":"2024-11-03T03:16:37.790351Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting remotezip\n  Downloading remotezip-0.12.3-py3-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.10.0.84)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from remotezip) (2.32.3)\nRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.26.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->remotezip) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->remotezip) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->remotezip) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->remotezip) (2024.8.30)\nDownloading remotezip-0.12.3-py3-none-any.whl (8.1 kB)\nInstalling collected packages: remotezip\nSuccessfully installed remotezip-0.12.3\n","output_type":"stream"}]},{"cell_type":"code","source":"import tqdm\nimport random\nimport pathlib\nimport itertools\n\nimport cv2\nimport numpy as np\nimport remotezip as rz\n\nimport tensorflow as tf\nimport keras\nfrom keras import layers","metadata":{"execution":{"iopub.status.busy":"2024-11-03T05:04:28.250844Z","iopub.execute_input":"2024-11-03T05:04:28.252004Z","iopub.status.idle":"2024-11-03T05:04:39.683266Z","shell.execute_reply.started":"2024-11-03T05:04:28.251935Z","shell.execute_reply":"2024-11-03T05:04:39.682426Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-11-03T05:04:39.684734Z","iopub.execute_input":"2024-11-03T05:04:39.685304Z","iopub.status.idle":"2024-11-03T05:04:39.929189Z","shell.execute_reply.started":"2024-11-03T05:04:39.685267Z","shell.execute_reply":"2024-11-03T05:04:39.928363Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def get_max_n_frames():\n    nonv = \"/kaggle/input/real-life-violence-situations-dataset/Real Life Violence Dataset/NonViolence\"\n    v = \"/kaggle/input/real-life-violence-situations-dataset/Real Life Violence Dataset/Violence\"\n    nonv_files = [nonv+\"/\"+f for f in os.listdir(nonv)]\n    v_files = [v+\"/\"+f for f in os.listdir(v)]\n    max_frame=0\n    removed_file = []\n    for cls in [nonv_files,v_files]:\n        for f in cls:\n            cap = cv2.VideoCapture(f)\n            n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n            if n_frames>1000:\n                removed_file.append(f)\n            else:\n                max_frame = max(max_frame,n_frames)\n    print(max_frame)\n    print(removed_file)\nget_max_n_frames()","metadata":{"execution":{"iopub.status.busy":"2024-11-03T03:16:52.009958Z","iopub.execute_input":"2024-11-03T03:16:52.010265Z","iopub.status.idle":"2024-11-03T03:17:13.038375Z","shell.execute_reply.started":"2024-11-03T03:16:52.010233Z","shell.execute_reply":"2024-11-03T03:17:13.037467Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"283\n['/kaggle/input/real-life-violence-situations-dataset/Real Life Violence Dataset/NonViolence/NV_992.mp4', '/kaggle/input/real-life-violence-situations-dataset/Real Life Violence Dataset/Violence/V_789.mp4', '/kaggle/input/real-life-violence-situations-dataset/Real Life Violence Dataset/Violence/V_398.mp4']\n","output_type":"stream"}]},{"cell_type":"code","source":"os.mkdir('data')\nos.mkdir('data/train')\nos.mkdir('data/test')\nos.mkdir('data/val')\nclasses = os.listdir(\"/kaggle/input/real-life-violence-situations-dataset/Real Life Violence Dataset\")\nnum_classes = len(classes)\n\ndata_videos = pd.DataFrame(columns=['class', 'path'])\n\nfor c in classes:\n    os.mkdir(f\"data/train/{c}\")\n    os.mkdir(f\"data/test/{c}\")\n    os.mkdir(f\"data/val/{c}\")\n    files = os.listdir(f\"/kaggle/input/real-life-violence-situations-dataset/Real Life Violence Dataset/{c}\")\n    if c == \"NonViolence\":\n        files.remove(\"NV_992.mp4\")\n    else:\n        files.remove(\"V_789.mp4\")\n        files.remove(\"V_398.mp4\")\n    temp =  pd.DataFrame([files,[c]*len(files)]).T\n    temp.columns = ['path', 'class']\n    data_videos = pd.concat([data_videos, temp])\n\ndata_videos = data_videos.sample(frac=1).reset_index(drop=True)\ndata_videos","metadata":{"execution":{"iopub.status.busy":"2024-11-03T05:04:47.948450Z","iopub.execute_input":"2024-11-03T05:04:47.949471Z","iopub.status.idle":"2024-11-03T05:04:48.272911Z","shell.execute_reply.started":"2024-11-03T05:04:47.949423Z","shell.execute_reply":"2024-11-03T05:04:48.271879Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"            class        path\n0     NonViolence  NV_984.mp4\n1        Violence   V_374.mp4\n2     NonViolence  NV_181.mp4\n3     NonViolence  NV_982.mp4\n4        Violence    V_58.mp4\n...           ...         ...\n1992     Violence   V_751.mp4\n1993  NonViolence  NV_979.mp4\n1994     Violence   V_494.mp4\n1995  NonViolence  NV_874.avi\n1996     Violence   V_527.mp4\n\n[1997 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NonViolence</td>\n      <td>NV_984.mp4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Violence</td>\n      <td>V_374.mp4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NonViolence</td>\n      <td>NV_181.mp4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NonViolence</td>\n      <td>NV_982.mp4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Violence</td>\n      <td>V_58.mp4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1992</th>\n      <td>Violence</td>\n      <td>V_751.mp4</td>\n    </tr>\n    <tr>\n      <th>1993</th>\n      <td>NonViolence</td>\n      <td>NV_979.mp4</td>\n    </tr>\n    <tr>\n      <th>1994</th>\n      <td>Violence</td>\n      <td>V_494.mp4</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>NonViolence</td>\n      <td>NV_874.avi</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>Violence</td>\n      <td>V_527.mp4</td>\n    </tr>\n  </tbody>\n</table>\n<p>1997 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train,test = train_test_split(data_videos, test_size=0.1,random_state=42)\ntrain,val = train_test_split(train, test_size=0.1,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T05:04:51.617673Z","iopub.execute_input":"2024-11-03T05:04:51.618140Z","iopub.status.idle":"2024-11-03T05:04:51.628158Z","shell.execute_reply.started":"2024-11-03T05:04:51.618101Z","shell.execute_reply":"2024-11-03T05:04:51.626891Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def move_files(subset,data):\n    if not subset in [\"train\",\"test\",\"val\"]:\n        return\n    else:\n        if subset == 'train':\n            destination = \"data/train\"\n        elif subset == \"test\":\n            destination = \"data/test\"\n        elif subset == \"val\":\n            destination = \"data/val\"\n        for i in range(len(data)):\n            path = f\"{data.iloc[i]['class']}/{data.iloc[i]['path']}\"\n            shutil.copy(f\"/kaggle/input/real-life-violence-situations-dataset/Real Life Violence Dataset/{path}\",f\"{destination}/{path}\")\n\nmove_files(\"train\",train)\nmove_files(\"test\",test)\nmove_files(\"val\",val)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T05:04:51.984519Z","iopub.execute_input":"2024-11-03T05:04:51.984896Z","iopub.status.idle":"2024-11-03T05:05:18.505654Z","shell.execute_reply.started":"2024-11-03T05:04:51.984861Z","shell.execute_reply":"2024-11-03T05:05:18.504818Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def process_frame(frame):\n    frame = tf.image.convert_image_dtype(frame, tf.float32)\n    frame = tf.image.resize(frame, size=(122, 122))\n    frame = frame/255.0\n    return frame\n\ndef read_frames_from_video(video_path):\n    src = cv2.VideoCapture(video_path)\n    length = int(src.get(cv2.CAP_PROP_FRAME_COUNT))\n    start = 283 - length\n    success = 1\n\n    frames = [np.zeros((122, 122,3)) for i in range(start)]\n\n    while success:\n        success, frame = src.read()\n        if frame is not None:\n            frame = process_frame(frame)\n            frames.append(frame)\n    src.release()\n    frames = np.array(frames)\n    return frames\n\ndef video_frame_generator(files, labels, batch_size=32):\n    images = []\n    labels_list = []\n    data = zip(files, labels)\n\n    for f, label in data:\n        frames = read_frames_from_video(f)\n\n        images.append(frames)\n        labels_list.append(label)\n\n        # Check if we have enough images for a batch\n        if len(images) == batch_size:\n            yield np.array(images), np.array(labels_list)\n            # Reset the lists for the next batch\n            images = []\n            labels_list = []\n\n    # Yield any remaining frames that didn't fill a complete batch\n    if images:\n        yield np.array(images), np.array(labels_list)\n\n\ndef getvideo(subset,data):\n    path = f\"data/{subset}\"\n    files = (data[\"class\"]+\"/\"+data[\"path\"]).tolist()\n    labels = (train[\"class\"].astype(\"category\").cat.codes).tolist()\n    return video_frame_generator(files,labels)\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T05:05:18.507250Z","iopub.execute_input":"2024-11-03T05:05:18.507577Z","iopub.status.idle":"2024-11-03T05:05:18.520294Z","shell.execute_reply.started":"2024-11-03T05:05:18.507543Z","shell.execute_reply":"2024-11-03T05:05:18.519328Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import itertools\n\ntrain_imgs = itertools.cycle(getvideo(\"train\",train))\ntest_imgs = itertools.cycle(getvideo(\"test\",test))\nval_imgs = itertools.cycle(getvideo(\"val\",val))","metadata":{"execution":{"iopub.status.busy":"2024-11-03T05:06:31.503898Z","iopub.execute_input":"2024-11-03T05:06:31.504830Z","iopub.status.idle":"2024-11-03T05:06:31.516243Z","shell.execute_reply.started":"2024-11-03T05:06:31.504785Z","shell.execute_reply":"2024-11-03T05:06:31.515177Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"for image,label in train_imgs:\n    print(image.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-11-03T05:00:38.690184Z","iopub.execute_input":"2024-11-03T05:00:38.690961Z","iopub.status.idle":"2024-11-03T05:00:42.222935Z","shell.execute_reply.started":"2024-11-03T05:00:38.690916Z","shell.execute_reply":"2024-11-03T05:00:42.221388Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"(32, 283, 122, 122, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2024-11-03T05:07:12.662250Z","iopub.execute_input":"2024-11-03T05:07:12.662643Z","iopub.status.idle":"2024-11-03T05:07:12.667725Z","shell.execute_reply.started":"2024-11-03T05:07:12.662607Z","shell.execute_reply":"2024-11-03T05:07:12.666713Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/tensorflow/models.git","metadata":{"execution":{"iopub.status.busy":"2024-11-03T03:17:34.266482Z","iopub.execute_input":"2024-11-03T03:17:34.266937Z","iopub.status.idle":"2024-11-03T03:17:57.789944Z","shell.execute_reply.started":"2024-11-03T03:17:34.266896Z","shell.execute_reply":"2024-11-03T03:17:57.789017Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Cloning into 'models'...\nremote: Enumerating objects: 98359, done.\u001b[K\nremote: Counting objects: 100% (866/866), done.\u001b[K\nremote: Compressing objects: 100% (467/467), done.\u001b[K\nremote: Total 98359 (delta 461), reused 717 (delta 376), pack-reused 97493 (from 1)\u001b[K\nReceiving objects: 100% (98359/98359), 621.96 MiB | 37.46 MiB/s, done.\nResolving deltas: 100% (71454/71454), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/working/models\")","metadata":{"execution":{"iopub.status.busy":"2024-11-03T05:07:15.183285Z","iopub.execute_input":"2024-11-03T05:07:15.183709Z","iopub.status.idle":"2024-11-03T05:07:15.190208Z","shell.execute_reply.started":"2024-11-03T05:07:15.183657Z","shell.execute_reply":"2024-11-03T05:07:15.189335Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"!pip install gin-config==0.1.1\n!pip install pycocotools","metadata":{"execution":{"iopub.status.busy":"2024-11-03T03:17:57.798333Z","iopub.execute_input":"2024-11-03T03:17:57.798662Z","iopub.status.idle":"2024-11-03T03:18:23.627621Z","shell.execute_reply.started":"2024-11-03T03:17:57.798630Z","shell.execute_reply":"2024-11-03T03:18:23.626553Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Collecting gin-config==0.1.1\n  Downloading gin-config-0.1.1.tar.gz (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from gin-config==0.1.1) (1.16.0)\nBuilding wheels for collected packages: gin-config\n  Building wheel for gin-config (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gin-config: filename=gin_config-0.1.1-py3-none-any.whl size=38309 sha256=0d4cf10f39a2fb18e376e3df5bf4873b2e3de21e2d1df0a69e99f861ff8bcd2d\n  Stored in directory: /root/.cache/pip/wheels/aa/ad/a7/b085ddc60427ebf0d52e1643eb4906911866690c004adbcc9d\nSuccessfully built gin-config\nInstalling collected packages: gin-config\nSuccessfully installed gin-config-0.1.1\nCollecting pycocotools\n  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools) (3.7.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pycocotools) (1.26.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\nDownloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.8/427.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pycocotools\nSuccessfully installed pycocotools-2.0.8\n","output_type":"stream"}]},{"cell_type":"code","source":"from official.projects.movinet.modeling import movinet_model\nfrom official.projects.movinet.modeling import movinet","metadata":{"execution":{"iopub.status.busy":"2024-11-03T05:07:19.461860Z","iopub.execute_input":"2024-11-03T05:07:19.462538Z","iopub.status.idle":"2024-11-03T05:07:21.088260Z","shell.execute_reply.started":"2024-11-03T05:07:19.462496Z","shell.execute_reply":"2024-11-03T05:07:21.087427Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model_id = 'a0'\nbackbone = movinet.Movinet(model_id=model_id)\nbackbone.trainable = False\n\ndef build_classifier(batch_size, num_frames, resolution, backbone, num_classes):\n    model = movinet_model.MovinetClassifier(backbone=backbone,num_classes=num_classes)\n    model.build([batch_size, num_frames, resolution, resolution, 3])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-11-03T05:07:21.089873Z","iopub.execute_input":"2024-11-03T05:07:21.090184Z","iopub.status.idle":"2024-11-03T05:07:55.895284Z","shell.execute_reply.started":"2024-11-03T05:07:21.090150Z","shell.execute_reply":"2024-11-03T05:07:55.894002Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Input, BatchNormalization","metadata":{"execution":{"iopub.status.busy":"2024-11-03T05:07:55.897440Z","iopub.execute_input":"2024-11-03T05:07:55.897810Z","iopub.status.idle":"2024-11-03T05:07:55.902960Z","shell.execute_reply.started":"2024-11-03T05:07:55.897771Z","shell.execute_reply":"2024-11-03T05:07:55.901919Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model = build_classifier(32, 283, 122, backbone, 2)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T05:07:55.904159Z","iopub.execute_input":"2024-11-03T05:07:55.904546Z","iopub.status.idle":"2024-11-03T05:08:09.031917Z","shell.execute_reply.started":"2024-11-03T05:07:55.904499Z","shell.execute_reply":"2024-11-03T05:08:09.031058Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"num_epochs = 100\nloss_obj = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nmodel.compile(loss=loss_obj, optimizer=\"adam\", metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-11-03T05:08:09.033996Z","iopub.execute_input":"2024-11-03T05:08:09.034316Z","iopub.status.idle":"2024-11-03T05:08:09.064011Z","shell.execute_reply.started":"2024-11-03T05:08:09.034282Z","shell.execute_reply":"2024-11-03T05:08:09.063269Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-11-03T04:05:47.521559Z","iopub.status.idle":"2024-11-03T04:05:47.522400Z","shell.execute_reply.started":"2024-11-03T04:05:47.521956Z","shell.execute_reply":"2024-11-03T04:05:47.522000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(train_imgs,validation_data=test_imgs,epochs=20)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T05:08:28.190280Z","iopub.execute_input":"2024-11-03T05:08:28.191306Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1730610562.186821   14368 service.cc:145] XLA service 0x7cf038016600 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1730610562.186912   14368 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1730610562.186918   14368 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1730610565.076074   14368 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n2024-11-03 05:09:31.712000: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng28{k2=2,k3=0} for conv (f32[32,24,283,31,31]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[32,24,283,61,61]{4,3,2,1,0}, f32[24,1,1,5,5]{4,3,2,1,0}), window={size=1x5x5 stride=1x2x2 pad=0_0x2_2x2_2}, dim_labels=bf012_oi012->bf012, feature_group_count=24, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n2024-11-03 05:09:32.229353: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.517444274s\nTrying algorithm eng28{k2=2,k3=0} for conv (f32[32,24,283,31,31]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[32,24,283,61,61]{4,3,2,1,0}, f32[24,1,1,5,5]{4,3,2,1,0}), window={size=1x5x5 stride=1x2x2 pad=0_0x2_2x2_2}, dim_labels=bf012_oi012->bf012, feature_group_count=24, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n2024-11-03 05:09:33.229607: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng42{k2=1,k4=1,k5=1,k6=0,k7=0} for conv (f32[32,24,283,31,31]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[32,24,283,61,61]{4,3,2,1,0}, f32[24,1,1,5,5]{4,3,2,1,0}), window={size=1x5x5 stride=1x2x2 pad=0_0x2_2x2_2}, dim_labels=bf012_oi012->bf012, feature_group_count=24, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n2024-11-03 05:09:37.274138: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 5.04465789s\nTrying algorithm eng42{k2=1,k4=1,k5=1,k6=0,k7=0} for conv (f32[32,24,283,31,31]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[32,24,283,61,61]{4,3,2,1,0}, f32[24,1,1,5,5]{4,3,2,1,0}), window={size=1x5x5 stride=1x2x2 pad=0_0x2_2x2_2}, dim_labels=bf012_oi012->bf012, feature_group_count=24, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n2024-11-03 05:10:03.165060: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng4{} for conv (f32[32,480,283,4,4]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[32,104,283,4,4]{4,3,2,1,0}, f32[480,104,1,1,1]{4,3,2,1,0}), window={size=1x1x1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n2024-11-03 05:10:03.306938: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.142064347s\nTrying algorithm eng4{} for conv (f32[32,480,283,4,4]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[32,104,283,4,4]{4,3,2,1,0}, f32[480,104,1,1,1]{4,3,2,1,0}), window={size=1x1x1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n","output_type":"stream"},{"name":"stdout","text":"      6/Unknown - 112s 5s/step - loss: 0.6920 - accuracy: 0.5260","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}